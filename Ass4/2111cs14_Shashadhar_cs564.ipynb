{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36f811b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,SimpleRNN\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e94074",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "062cda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"bbc.csv\")\n",
    "\n",
    "#Dropping the irrelevant first column\n",
    "data=data.drop(data.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90167e62",
   "metadata": {},
   "source": [
    "## Splitting data to train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f7b05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(data['Article'],data['Class'],test_size=0.2,train_size=0.8,random_state=35)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.1,random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02da410",
   "metadata": {},
   "source": [
    "## Tokenizing the sentences and aligning the data with the max length <br>Added padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82416b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 1, 4, 1, 2, 1, 5, 2, 1, 4, 3, 2, 2, 3, 2, 2, 3, 4, 2, 2, 1,\n",
       "       5, 2, 4, 3, 1, 3, 3, 1, 1, 2, 2, 5, 1, 3, 1, 5, 5, 4, 5, 2, 1, 1,\n",
       "       3, 1, 1, 4, 3, 3, 2, 1, 4, 4, 1, 4, 2, 3, 2, 1, 2, 3, 4, 1, 2, 1,\n",
       "       2, 3, 4, 4, 1, 4, 2, 3, 3, 3, 1, 3, 3, 4, 5, 4, 3, 1, 4, 1, 4, 2,\n",
       "       4, 1, 3, 3, 1, 4, 1, 1, 1, 4, 2, 5, 4, 1, 2, 2, 1, 4, 1, 2, 4, 2,\n",
       "       1, 4, 2, 1, 4, 1, 1, 2, 2, 4, 4, 2, 2, 2, 3, 4, 4, 3, 1, 5, 2, 3,\n",
       "       4, 4, 2, 2, 1, 2, 3, 2, 1, 1, 3, 2, 4, 1, 3, 3, 3, 2, 4, 2, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padding the sentences to a particular length so that we can feed that to our NN\n",
    "#converting the target class to number\n",
    "tokenizer = Tokenizer(num_words = 10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(np.array(X_train))\n",
    "text_word_index = tokenizer.word_index\n",
    "text_sequences = tokenizer.texts_to_sequences(np.array(X_train))\n",
    "X_train_final = pad_sequences(text_sequences, padding='post', maxlen=100)\n",
    "class_tokenizer = Tokenizer()\n",
    "class_tokenizer.fit_on_texts(np.array(y_train))\n",
    "class_word_index = class_tokenizer.word_index\n",
    "y_train_final = np.array(class_tokenizer.texts_to_sequences(np.array(y_train)))\n",
    "y_train_final.reshape(y_train_final.shape[0],)\n",
    "\n",
    "#doing the tokenization and padding for the test and validation set also\n",
    "test_text_sequences = tokenizer.texts_to_sequences(np.array(X_test))\n",
    "X_test_final = pad_sequences(test_text_sequences, padding='post', maxlen=100)\n",
    "y_test_final = np.array(class_tokenizer.texts_to_sequences(np.array(y_test)))\n",
    "y_test_final.reshape(y_test_final.shape[0],)\n",
    "validation_text_sequences = tokenizer.texts_to_sequences(np.array(X_val))\n",
    "X_val_final = pad_sequences(validation_text_sequences, padding='post', maxlen=100)\n",
    "y_val_final = np.array(class_tokenizer.texts_to_sequences(np.array(y_val)))\n",
    "y_val_final.reshape(y_val_final.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c938de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating these to store model and accuracies\n",
    "models=list()\n",
    "accuracies=list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e8f34",
   "metadata": {},
   "source": [
    "## Creating the vanilla RNN model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0703e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 9s 138ms/step - loss: 1.6785 - accuracy: 0.2151 - val_loss: 1.5637 - val_accuracy: 0.2876\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 1.5951 - accuracy: 0.2573 - val_loss: 1.5926 - val_accuracy: 0.2876\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 1.5569 - accuracy: 0.2907 - val_loss: 1.5158 - val_accuracy: 0.3595\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 1.5115 - accuracy: 0.3256 - val_loss: 1.5251 - val_accuracy: 0.2941\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 1.1533 - accuracy: 0.6199 - val_loss: 1.4141 - val_accuracy: 0.3791\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 5s 111ms/step - loss: 0.2570 - accuracy: 0.9455 - val_loss: 1.8627 - val_accuracy: 0.3464\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.0277 - accuracy: 0.9985 - val_loss: 1.9613 - val_accuracy: 0.3529\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.9596 - val_accuracy: 0.3137\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0050 - val_accuracy: 0.3203\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "RNNmodel = tf.keras.Sequential([\n",
    "tf.keras.layers.Embedding(10000, 200, input_length=100),\n",
    "tf.keras.layers.SimpleRNN(100,input_shape=(100,6),return_sequences = False),\n",
    "tf.keras.layers.Dense(64, activation='relu'),\n",
    "tf.keras.layers.Dense(24, activation='relu'),\n",
    "tf.keras.layers.Dense(6, activation='softmax'),\n",
    "])\n",
    "RNNmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history1=RNNmodel.fit(X_train_final,y_train_final,epochs=10,validation_data=(X_val_final,y_val_final),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8d772",
   "metadata": {},
   "source": [
    "## Accuracy of vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04b290ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2, 4, 4, 4, 5, 2, 2, 1, 4, 2, 1, 5, 4, 1, 4, 3, 2, 1, 4, 5, 1, 5, 1, 3, 3, 4, 3, 4, 2, 3, 5, 2, 3, 3, 4, 3, 5, 2, 2, 4, 4, 5, 4, 2, 3, 1, 5, 1, 1, 3, 4, 3, 3, 3, 1, 3, 5, 3, 5, 1, 1, 2, 5, 2, 4, 3, 2, 2, 4, 2, 4, 3, 1, 3, 3, 3, 3, 3, 2, 2, 4, 2, 1, 4, 5, 2, 1, 3, 4, 3, 4, 2, 3, 4, 3, 5, 4, 5, 3, 1, 2, 3, 1, 4, 2, 4, 3, 2, 1, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 1, 4, 4, 1, 1, 2, 4, 1, 1, 3, 2, 3, 1, 2, 1, 3, 3, 1, 5, 2, 1, 3, 4, 5, 5, 3, 2, 1, 2, 3, 1, 2, 4, 3, 3, 4, 4, 4, 5, 4, 3, 2, 2, 1, 4, 2, 4, 4, 4, 1, 2, 2, 5, 2, 2, 3, 1, 1, 3, 4, 2, 3, 1, 2, 4, 2, 3, 5, 5, 2, 4, 4, 2, 4, 1, 2, 4, 5, 3, 3, 2, 1, 4, 2, 3, 4, 5, 4, 1, 1, 4, 1, 2, 4, 2, 1, 4, 5, 4, 4, 1, 5, 5, 4, 4, 4, 3, 4, 3, 2, 4, 3, 3, 4, 2, 4, 3, 3, 3, 3, 4, 2, 1, 4, 4, 2, 2, 4, 1, 4, 4, 1, 2, 4, 3, 4, 4, 2, 4, 4, 5, 4, 2, 2, 4, 4, 5, 5, 2, 4, 4, 2, 2, 5, 3, 3, 1, 1, 3, 3, 4, 3, 2, 1, 1, 1, 5, 5, 5, 1, 1, 2, 4, 4, 5, 4, 3, 4, 1, 4, 4, 5, 4, 4, 1, 4, 4, 4, 1, 4, 4, 4, 1, 1, 3, 4, 4, 4, 4, 4, 1, 1, 3, 1, 1, 4, 2, 4, 1, 5, 1, 4, 3, 1, 2, 1, 5, 1, 5, 1, 4, 5, 1, 5, 3, 4, 1, 1, 5, 4, 5, 1, 5, 3, 2, 3, 2, 4, 4, 1, 4, 2, 3, 1, 1, 2, 1, 2, 4, 1, 1, 1, 1, 1, 2, 2, 3, 2, 5, 2, 5, 2, 3, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.41      0.46       105\n",
      "           2       0.29      0.28      0.29        74\n",
      "           3       0.56      0.51      0.53        83\n",
      "           4       0.32      0.41      0.36        82\n",
      "           5       0.20      0.23      0.21        39\n",
      "\n",
      "    accuracy                           0.39       383\n",
      "   macro avg       0.38      0.37      0.37       383\n",
      "weighted avg       0.41      0.39      0.39       383\n",
      "\n",
      "Accuracy of vanilla RNN on test data is :  38.90339425587467\n"
     ]
    }
   ],
   "source": [
    "models.append(RNNmodel)\n",
    "y_pred_1=RNNmodel.predict(X_test_final)\n",
    "real=[]\n",
    "for i in range(len(y_test_final)):\n",
    "    real.append(y_test_final[i][0])\n",
    "predictions1=[]\n",
    "for i in range(len(y_pred_1)):\n",
    "    predictions1.append(np.argmax(y_pred_1[i]))\n",
    "accuracy1=(accuracy_score(predictions1,real))*100\n",
    "accuracies.append(history1.history['val_accuracy'][-1]*100)\n",
    "print(\"Predictions:\",predictions1)\n",
    "print(classification_report(real, predictions1, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\"]))\n",
    "print(\"Accuracy of vanilla RNN on test data is : \",accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b041a8",
   "metadata": {},
   "source": [
    "## Creating the old FFN model from assignment 4 and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1831b23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 2s 32ms/step - loss: 1.6174 - accuracy: 0.2798 - val_loss: 1.3951 - val_accuracy: 0.4641\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 1.1147 - accuracy: 0.6577 - val_loss: 0.9121 - val_accuracy: 0.7516\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.5702 - accuracy: 0.8932 - val_loss: 0.6241 - val_accuracy: 0.7974\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.2412 - accuracy: 0.9724 - val_loss: 0.4706 - val_accuracy: 0.8301\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.1006 - accuracy: 0.9978 - val_loss: 0.3980 - val_accuracy: 0.8497\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8562\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.8758\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# tanh activation is used\n",
    "oldFFNmodel = tf.keras.Sequential([\n",
    "tf.keras.layers.Embedding(10000, 200, input_length=100),\n",
    "tf.keras.layers.GlobalAveragePooling1D(),\n",
    "tf.keras.layers.Dense(64, activation='tanh'),\n",
    "tf.keras.layers.Dense(24, activation='tanh'),\n",
    "tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "oldFFNmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history2=oldFFNmodel.fit(X_train_final,y_train_final,epochs=10,validation_data=(X_val_final,y_val_final),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68eaf5",
   "metadata": {},
   "source": [
    "## Accuracy of old FFN model from assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "270028f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1, 1, 3, 3, 4, 4, 2, 1, 2, 4, 5, 5, 1, 5, 4, 3, 4, 3, 4, 1, 2, 3, 3, 3, 3, 4, 3, 3, 3, 3, 1, 3, 3, 1, 3, 2, 2, 1, 3, 4, 1, 1, 1, 2, 1, 1, 2, 5, 3, 3, 2, 3, 4, 3, 5, 4, 4, 1, 1, 5, 1, 1, 2, 5, 5, 2, 1, 5, 2, 3, 4, 4, 1, 1, 3, 3, 3, 3, 3, 2, 1, 1, 1, 4, 1, 2, 1, 3, 1, 5, 3, 3, 1, 4, 1, 1, 3, 4, 3, 1, 4, 3, 1, 4, 3, 1, 3, 4, 1, 3, 1, 1, 2, 1, 3, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 4, 1, 4, 5, 2, 1, 4, 3, 1, 5, 1, 1, 4, 2, 1, 4, 1, 5, 5, 3, 1, 1, 1, 3, 4, 2, 4, 5, 3, 4, 4, 4, 4, 1, 3, 2, 2, 4, 4, 5, 4, 4, 2, 2, 3, 2, 2, 1, 3, 4, 1, 1, 4, 1, 4, 3, 3, 3, 5, 3, 1, 4, 4, 3, 4, 4, 4, 1, 1, 3, 1, 1, 3, 3, 1, 4, 1, 3, 3, 4, 5, 4, 1, 3, 3, 1, 2, 3, 5, 1, 1, 1, 1, 2, 2, 2, 4, 1, 2, 4, 3, 4, 3, 1, 2, 2, 3, 5, 2, 4, 4, 3, 3, 1, 4, 4, 3, 4, 1, 1, 2, 4, 1, 5, 4, 4, 2, 4, 3, 5, 1, 3, 5, 3, 2, 4, 2, 1, 4, 4, 1, 3, 4, 2, 2, 3, 3, 5, 3, 3, 1, 2, 2, 1, 5, 3, 1, 3, 2, 1, 2, 2, 5, 1, 4, 4, 2, 1, 3, 4, 4, 3, 2, 2, 2, 4, 5, 4, 1, 2, 5, 4, 1, 2, 4, 2, 5, 1, 2, 1, 3, 4, 2, 3, 3, 3, 2, 1, 3, 3, 2, 4, 5, 3, 1, 3, 4, 3, 4, 1, 1, 1, 1, 1, 2, 5, 2, 5, 3, 4, 1, 4, 4, 5, 3, 2, 1, 3, 2, 3, 4, 2, 1, 3, 4, 4, 3, 1, 2, 1, 1, 1, 3, 4, 1, 4, 2, 3, 3, 2, 5, 1, 3, 5, 5, 4, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.92      0.91       105\n",
      "           2       0.90      0.76      0.82        74\n",
      "           3       0.82      0.93      0.87        83\n",
      "           4       0.86      0.87      0.86        82\n",
      "           5       0.97      0.90      0.93        39\n",
      "\n",
      "    accuracy                           0.88       383\n",
      "   macro avg       0.89      0.87      0.88       383\n",
      "weighted avg       0.88      0.88      0.88       383\n",
      "\n",
      "Accuracy of old FFN on test data is :  87.72845953002611\n"
     ]
    }
   ],
   "source": [
    "models.append(oldFFNmodel)\n",
    "y_pred_2=oldFFNmodel.predict(X_test_final)\n",
    "real=[]\n",
    "for i in range(len(y_test_final)):\n",
    "    real.append(y_test_final[i][0])\n",
    "predictions2=[]\n",
    "for i in range(len(y_pred_2)):\n",
    "    predictions2.append(np.argmax(y_pred_2[i]))\n",
    "accuracy2=(accuracy_score(predictions2,real))*100\n",
    "accuracies.append(history2.history['val_accuracy'][-1]*100)\n",
    "print(\"Predictions:\",predictions2)\n",
    "print(classification_report(real, predictions2, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\"]))\n",
    "print(\"Accuracy of old FFN on test data is : \",accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfb46e",
   "metadata": {},
   "source": [
    "## Creating the new FFN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d56c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "newFFNmodel = tf.keras.Sequential([\n",
    "tf.keras.layers.Embedding(10000, 200, input_length=100),\n",
    "tf.keras.layers.GlobalAveragePooling1D(),\n",
    "tf.keras.layers.Dense(64, activation='tanh'),\n",
    "tf.keras.layers.Dense(24, activation='tanh'),\n",
    "tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "newFFNmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221fc64",
   "metadata": {},
   "source": [
    "## Initializing the weights of the new FFN model with the near-optimal weights of the old FFN model from assignment 4 (the near-optimal weights are taken after training the old FFN model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1c4ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_tg,l_sr in zip(oldFFNmodel.layers,newFFNmodel.layers):\n",
    "    if l_tg!='global_average_pooling1d_2' and l_sr!='global_average_pooling1d_2':\n",
    "        wk0=l_sr.get_weights()\n",
    "        l_tg.set_weights(wk0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b0b2b",
   "metadata": {},
   "source": [
    "## Training the new FFN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "086c6e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43/43 [==============================] - 2s 31ms/step - loss: 1.6266 - accuracy: 0.2827 - val_loss: 1.3952 - val_accuracy: 0.5425\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 1.1042 - accuracy: 0.7420 - val_loss: 0.8599 - val_accuracy: 0.8105\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.4895 - accuracy: 0.9324 - val_loss: 0.4918 - val_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1670 - accuracy: 0.9826 - val_loss: 0.3632 - val_accuracy: 0.9020\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0634 - accuracy: 0.9978 - val_loss: 0.3144 - val_accuracy: 0.9020\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0309 - accuracy: 0.9993 - val_loss: 0.2938 - val_accuracy: 0.9216\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9216\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9281\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "history3=newFFNmodel.fit(X_train_final,y_train_final,epochs=10,validation_data=(X_val_final,y_val_final),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cffac1",
   "metadata": {},
   "source": [
    "## Accuracy of new FFN model (initialized with near-optimal weights obtained from and after training old FFN model from assignment 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a57dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1, 1, 3, 3, 4, 4, 2, 1, 4, 4, 5, 5, 1, 5, 4, 3, 4, 3, 5, 1, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 1, 1, 3, 1, 3, 2, 2, 1, 3, 4, 1, 1, 1, 2, 1, 1, 2, 5, 3, 3, 2, 3, 4, 3, 5, 4, 4, 1, 1, 2, 1, 3, 2, 5, 4, 2, 1, 5, 2, 3, 4, 4, 1, 1, 3, 3, 3, 3, 3, 2, 1, 1, 1, 4, 1, 2, 1, 3, 1, 5, 1, 3, 3, 4, 1, 1, 3, 4, 1, 4, 4, 3, 1, 5, 3, 1, 3, 4, 1, 3, 1, 1, 2, 1, 3, 1, 1, 2, 3, 1, 4, 1, 1, 1, 4, 4, 1, 4, 5, 2, 1, 4, 3, 1, 5, 1, 1, 4, 2, 1, 4, 1, 5, 5, 3, 1, 1, 1, 3, 4, 2, 4, 5, 3, 4, 4, 4, 4, 1, 3, 2, 2, 4, 4, 5, 4, 4, 2, 2, 3, 2, 2, 1, 3, 4, 1, 1, 4, 1, 2, 3, 3, 1, 5, 1, 1, 2, 4, 3, 4, 4, 4, 1, 1, 1, 1, 1, 3, 3, 1, 4, 4, 3, 3, 4, 5, 4, 1, 3, 3, 1, 2, 3, 5, 1, 1, 1, 1, 2, 2, 2, 4, 2, 2, 4, 3, 4, 3, 1, 2, 2, 3, 5, 2, 5, 4, 3, 3, 1, 4, 4, 1, 4, 1, 1, 2, 4, 1, 5, 4, 4, 2, 4, 3, 5, 1, 3, 5, 3, 2, 4, 2, 1, 4, 4, 1, 3, 4, 2, 2, 3, 3, 5, 3, 3, 1, 2, 4, 1, 5, 3, 1, 1, 2, 1, 2, 2, 5, 1, 4, 4, 2, 1, 3, 4, 2, 3, 2, 2, 2, 4, 5, 4, 1, 2, 5, 4, 1, 2, 4, 2, 5, 1, 3, 1, 3, 4, 2, 3, 3, 3, 2, 1, 3, 3, 2, 3, 5, 3, 1, 3, 4, 3, 4, 1, 1, 1, 1, 1, 2, 5, 2, 5, 3, 4, 1, 4, 4, 5, 3, 2, 1, 3, 2, 3, 1, 2, 1, 1, 4, 4, 3, 1, 2, 1, 1, 1, 2, 4, 1, 4, 2, 1, 3, 5, 5, 1, 3, 5, 5, 4, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.92      0.89       105\n",
      "           2       0.91      0.80      0.85        74\n",
      "           3       0.88      0.92      0.90        83\n",
      "           4       0.90      0.88      0.89        82\n",
      "           5       0.95      0.92      0.94        39\n",
      "\n",
      "    accuracy                           0.89       383\n",
      "   macro avg       0.90      0.89      0.89       383\n",
      "weighted avg       0.89      0.89      0.89       383\n",
      "\n",
      "Accuracy of old FFN on test data is :  88.77284595300262\n"
     ]
    }
   ],
   "source": [
    "models.append(newFFNmodel)\n",
    "y_pred_3=newFFNmodel.predict(X_test_final)\n",
    "real=[]\n",
    "for i in range(len(y_test_final)):\n",
    "    real.append(y_test_final[i][0])\n",
    "predictions3=[]\n",
    "for i in range(len(y_pred_3)):\n",
    "    predictions3.append(np.argmax(y_pred_3[i]))\n",
    "accuracy3=(accuracy_score(predictions3,real))*100\n",
    "accuracies.append(history3.history['val_accuracy'][-1]*100)\n",
    "print(\"Predictions:\",predictions3)\n",
    "print(classification_report(real, predictions3, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\"]))\n",
    "print(\"Accuracy of old FFN on test data is : \",accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a285efc",
   "metadata": {},
   "source": [
    "## Creating the majority voting ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9526626",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_pred = []\n",
    "for i in range(0,len(predictions1)):\n",
    "    if predictions1[i] == predictions2[i]:\n",
    "        E_pred.append( predictions1[i])\n",
    "    elif predictions2[i] == predictions3[i]:\n",
    "        E_pred.append(predictions2[i])\n",
    "    elif predictions1[i] == predictions3[i]:\n",
    "        E_pred.append(predictions1[i])\n",
    "    else:\n",
    "        E_pred.append(predictions2[i])\n",
    "E_pred1 = E_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e96bcf",
   "metadata": {},
   "source": [
    "## Accuracy of the majority voting ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58ada187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.94      0.92       105\n",
      "           2       0.93      0.77      0.84        74\n",
      "           3       0.85      0.94      0.89        83\n",
      "           4       0.85      0.88      0.86        82\n",
      "           5       0.97      0.87      0.92        39\n",
      "\n",
      "    accuracy                           0.89       383\n",
      "   macro avg       0.90      0.88      0.89       383\n",
      "weighted avg       0.89      0.89      0.89       383\n",
      "\n",
      "Majority voting ensemble accuracy on test data is :  88.77284595300262\n"
     ]
    }
   ],
   "source": [
    "accuracy4=(accuracy_score(E_pred1,real))*100\n",
    "print(classification_report(real, E_pred1, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\"]))\n",
    "print(\"Majority voting ensemble accuracy on test data is : \",accuracy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fc648",
   "metadata": {},
   "source": [
    "## Creating the weighted voting ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6de3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = accuracies\n",
    "E_pred = []\n",
    "sum_acc = accuracies[0]+accuracies[1]+accuracies[2]\n",
    "for i in range(0,len(predictions1)):\n",
    "    E_pred.append(round((accuracies[0]*predictions1[i]+accuracies[1]*predictions2[i]+accuracies[2]*predictions3[i])/sum_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891229c0",
   "metadata": {},
   "source": [
    "## Accuracy of the weighted voting ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5077e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1, 1, 3, 3, 4, 4, 2, 1, 3, 4, 4, 5, 1, 4, 4, 3, 4, 3, 4, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 1, 3, 2, 2, 1, 3, 4, 1, 2, 1, 2, 1, 1, 2, 4, 3, 3, 2, 3, 4, 3, 4, 4, 4, 1, 2, 3, 1, 2, 2, 5, 4, 2, 1, 5, 2, 3, 4, 4, 1, 1, 3, 3, 3, 3, 3, 2, 1, 1, 1, 4, 2, 2, 1, 3, 1, 5, 2, 3, 2, 4, 1, 2, 3, 4, 2, 2, 4, 3, 1, 4, 3, 1, 3, 4, 1, 3, 1, 1, 2, 1, 3, 1, 1, 2, 3, 1, 4, 1, 1, 1, 2, 4, 1, 4, 5, 2, 1, 4, 3, 1, 5, 1, 1, 4, 2, 1, 4, 1, 5, 5, 3, 1, 1, 1, 3, 4, 2, 4, 5, 3, 4, 4, 4, 4, 1, 3, 2, 2, 4, 4, 5, 4, 4, 2, 2, 3, 2, 2, 1, 3, 4, 1, 1, 4, 1, 3, 3, 3, 2, 5, 2, 1, 3, 4, 3, 4, 4, 4, 1, 1, 2, 1, 2, 3, 3, 1, 4, 3, 3, 3, 4, 5, 4, 1, 3, 3, 1, 2, 3, 5, 1, 1, 2, 1, 2, 2, 2, 4, 2, 2, 4, 3, 4, 3, 1, 2, 2, 3, 5, 2, 4, 4, 3, 3, 1, 4, 4, 2, 4, 1, 1, 2, 4, 1, 5, 4, 4, 2, 4, 3, 5, 1, 3, 5, 3, 2, 4, 2, 1, 4, 4, 2, 3, 4, 2, 2, 3, 3, 5, 3, 3, 1, 2, 3, 1, 5, 3, 1, 2, 2, 1, 2, 2, 5, 1, 4, 4, 2, 1, 3, 4, 3, 3, 2, 2, 2, 4, 5, 4, 1, 2, 5, 4, 1, 2, 4, 2, 4, 1, 3, 1, 3, 4, 2, 3, 3, 3, 2, 1, 3, 3, 2, 4, 4, 3, 1, 3, 4, 3, 4, 1, 2, 1, 2, 1, 2, 5, 2, 5, 3, 4, 1, 4, 4, 5, 3, 2, 2, 3, 2, 3, 2, 2, 1, 2, 4, 4, 3, 1, 2, 1, 1, 1, 3, 4, 1, 4, 2, 2, 3, 3, 5, 1, 3, 5, 5, 4, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.78      0.84       105\n",
      "           2       0.68      0.80      0.73        74\n",
      "           3       0.82      0.92      0.86        83\n",
      "           4       0.81      0.84      0.83        82\n",
      "           5       1.00      0.72      0.84        39\n",
      "\n",
      "    accuracy                           0.82       383\n",
      "   macro avg       0.84      0.81      0.82       383\n",
      "weighted avg       0.83      0.82      0.82       383\n",
      "\n",
      "Weighted voting ensemble accuracy on test Data is :  81.98433420365535\n"
     ]
    }
   ],
   "source": [
    "accuracy5=(accuracy_score(E_pred,real))*100\n",
    "print(\"Predictions:\",E_pred)\n",
    "print(classification_report(real, E_pred, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\"]))\n",
    "print(\"Weighted voting ensemble accuracy on test Data is : \",accuracy5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61146b9d",
   "metadata": {},
   "source": [
    "## Number of instances misclassified in vanilla RNN model but correctly classified in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af226cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances misclassified in vanilla RNN model but correctly classified in the ensemble model:  198\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "for i in range(0,len(predictions1)):\n",
    "    if predictions1[i] != real[i] and E_pred1[i] == real[i]:\n",
    "        count1 += 1\n",
    "print(\"Number of instances misclassified in vanilla RNN model but correctly classified in the ensemble model: \", count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc537d",
   "metadata": {},
   "source": [
    "## Number of instances misclassified in old FFN model but correctly classified in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78d042d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances misclassified in old FFN model but correctly classified in the ensemble model:  7\n"
     ]
    }
   ],
   "source": [
    "count2 = 0\n",
    "for i in range(0,len(predictions2)):\n",
    "    if predictions2[i] != real[i] and E_pred1[i] == real[i]:\n",
    "        count2 += 1\n",
    "print(\"Number of instances misclassified in old FFN model but correctly classified in the ensemble model: \", count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c6acd",
   "metadata": {},
   "source": [
    "## Number of instances misclassified in new FFN model but correctly classified in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be340e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances misclassified in old FFN model but correctly classified in the ensemble model:  7\n"
     ]
    }
   ],
   "source": [
    "count3 = 0\n",
    "for i in range(0,len(predictions3)):\n",
    "    if predictions3[i] != real[i] and E_pred1[i] == real[i]:\n",
    "        count3 += 1\n",
    "print(\"Number of instances misclassified in old FFN model but correctly classified in the ensemble model: \", count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d489b52",
   "metadata": {},
   "source": [
    "## Number of instances wrongly classified by all three models but correctly classified by the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5c74fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances wrongly classified by all three models but correctly classified by the ensemble:  1\n"
     ]
    }
   ],
   "source": [
    "count4 = 0\n",
    "for i in range(0,len(predictions1)):\n",
    "    if predictions1[i] != real[i] and predictions2[i] != real[i] and predictions3[i] != real[i] and E_pred[i] == real[i]:\n",
    "        count4 += 1\n",
    "print(\"Number of instances wrongly classified by all three models but correctly classified by the ensemble: \", count4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d59980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
